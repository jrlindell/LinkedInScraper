{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_resume_parser(path):\n",
    "\n",
    "    import re\n",
    "    import io\n",
    "    import io\n",
    "    from pdfminer.converter import TextConverter\n",
    "    from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "    from pdfminer.pdfinterp import PDFResourceManager\n",
    "    from pdfminer.pdfpage import PDFPage\n",
    "    from docx2pdf import convert\n",
    "    from pdfminer.layout import LAParams\n",
    "    from pyresparser import ResumeParser\n",
    "    from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "    import pdfplumber\n",
    "    \n",
    "    import firebase_admin\n",
    "    from firebase_admin import credentials\n",
    "    from firebase_admin import firestore\n",
    "    from firebase_admin import db\n",
    "    \n",
    "\n",
    "    #========================================Splitting the pdf-------\n",
    "    pdf = pdfplumber.open(path)\n",
    "    end = '\"@@system.status.new\"'\n",
    "    inputpdf = PdfFileReader(open(path, \"rb\"))\n",
    "    output = PdfFileWriter()\n",
    "    endingPageList=[]\n",
    "    pdfNameList=[]\n",
    "    num=1\n",
    "    for i in range(inputpdf.numPages):\n",
    "        page = pdf.pages[i]\n",
    "        text = page.extract_text()\n",
    "        if text is not None:\n",
    "            if end in text:\n",
    "                with open(\"Resume%s.pdf\" % num, \"wb\") as outputStream:\n",
    "                    output.write(outputStream)\n",
    "                    pdfNameList.append(\"Resume\"+str(num)+\".pdf\")\n",
    "                output = PdfFileWriter()\n",
    "                num=num+1\n",
    "                continue\n",
    "            else:\n",
    "                output.addPage(inputpdf.getPage(i))\n",
    "    \n",
    "    #========================================Function to extract raw text from the pdf-------\n",
    "    def get_text_from_pdf(path):\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        retstr = io.StringIO()\n",
    "        codec = 'utf-8'\n",
    "\n",
    "        laparams = LAParams(line_overlap=.6, char_margin=1.5, line_margin=1.1, word_margin=0.3, boxes_flow=.6,\n",
    "                             detect_vertical=False, all_texts=False)\n",
    "        device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "        fp = open(path, 'rb')\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        password = \"\"\n",
    "        maxpages = 0\n",
    "        caching = True\n",
    "        pagenos = set()\n",
    "        for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching,\n",
    "                                      check_extractable=True):\n",
    "            interpreter.process_page(page)\n",
    "        fp.close()\n",
    "        device.close()\n",
    "        string = retstr.getvalue()\n",
    "\n",
    "        retstr.close()\n",
    "        return string\n",
    "    \n",
    "        #====================================Cleaning the raw text============================\n",
    "    canList=[]\n",
    "    for resume in pdfNameList:\n",
    "        read = get_text_from_pdf(resume)\n",
    "        if os.path.getsize(resume)<1000:\n",
    "            continue\n",
    "        read = read.replace('\\u25c6',' ')\n",
    "        read = read.replace('➤➤',' ')\n",
    "        read = read.replace('•',' ')\n",
    "        read = read.replace('▶️',' ')\n",
    "        read = read.replace('□',' ')\n",
    "        read = read.replace('\\x0c','')\n",
    "        read = read.replace('\\xa0','')\n",
    "\n",
    "        read = read.replace('\\n\\n','\\n')\n",
    "\n",
    "        #========================================Gathering Skills information-------\n",
    "        languages = {}\n",
    "        applications = {}\n",
    "        methods = {}\n",
    "        delivery = {}\n",
    "        impact ={}\n",
    "        communication = {}\n",
    "\n",
    "        lang = ['C#/.NET', 'C/C++', 'Go', 'Java', 'Javascript', 'Julia', 'MATLAB', 'PHP', 'R', 'Ruby', 'Scala', 'Visual Basic/VBA', 'Python', 'SQL', 'SAS']\n",
    "        appli = ['Computer Vision', 'Advesarial Machine Learning','Machine Learning', 'Auto-ML', 'Basic Neural Networks', 'Neural Networks', 'Linear Regression', 'Logistic Regression', 'Regression','Convolutional Neural Networks', 'Generative Models', 'LSTMs', 'LSTM', 'Natural Language Processing', 'NLP', 'Predictive Models', 'Recurrent Neural Networks', 'Reinforcement Learning', 'Supervised Learning', 'Unsupervised Learning', 'Voice & Audio Processing']\n",
    "        metho = ['Clustering','Data Analysis', 'Data Extraction', ' Data Compilation', 'Data Cleaning', 'Decision Analysis', 'Design of Experiments', 'Discrete Event Simulation', 'Game Theory', 'Linear & Integer Optimization', 'Multivariate Testing', 'Nonparametric Statistics', 'Parametric Statistics', 'Segmentation', 'Simulation', 'Monte Carlo', 'Stochastic Programming']\n",
    "        deliv = ['Alteryx Analytics','Amazon Web Services','AWS', 'Anaconda','Apache Airflow','Apache Beam','Apache Hadoop','Hadoop','Hive','Apache Hive','Apache Spark','Apachec Kafka','Kafka','Caffe','Cassandra','Cloudera Workbench','Couchbase','Databricks','Dataiku','DataScience.com','Docker','Domino','Google Bigtable','Google Cloud Platform','GCP','H2O.ai','IBM Watson Studio','Keras','KNIME Analytics','Kubernetes/Kubeflow','MapReduce','MATLAB','MATLAB/Octave','Microsoft Azure','Azure','Microsoft R','MongoDB','MXnet','MySQL','Pandas','PostgreSQL','RapidMiner Studio','SAP Predictive Analytics','SAS Enterprise Miner', 'SAS EM', 'SAS', 'Tableau','TensorFlow','Teradata Analytics','TIBCO Data Science','Wolfram Mathematica']\n",
    "        imp = ['Asset Utilization','Churn Prevention','Cost Optimization','Cross-/Upselling','Customer Analysis','Customer Experience','Debt Management','Demand Planning','E-Commerce','Fraud Prevention','Marketing Spend','Operational efficiencies','Predictive Maintenance','Pricing','Product Development','Promotion Optimization','Research & Development','Supply Chain Optimization','Workforce Planning']\n",
    "        comm = ['Presentation Skills','Storytelling','Data Visualization','Writing Skills','Social Media Skills','Emotional Intelligence','Business Acumen']\n",
    "\n",
    "\n",
    "        res=read.lower()\n",
    "        skills=[]\n",
    "        for i in lang:\n",
    "            if res.find(' '+i.lower()+' ') != -1:\n",
    "                languages[i] = 1\n",
    "\n",
    "\n",
    "        for j in appli:\n",
    "            if res.find(' '+j.lower()+' ') != -1:\n",
    "                applications[j] = 1\n",
    "\n",
    "        for k in metho:\n",
    "            if res.find(' '+k.lower()+' ') != -1:\n",
    "                methods[k] = 1\n",
    "\n",
    "        for l in deliv:\n",
    "            if res.find(' '+l.lower()+' ') != -1:\n",
    "                delivery[l] = 1\n",
    "\n",
    "        for m in imp:\n",
    "            if res.find(' '+m.lower()+' ') != -1:\n",
    "                impact[m] = 1\n",
    "\n",
    "        for n in comm:\n",
    "            if res.find(' '+n.lower()+' ') != -1:\n",
    "                communication[n] = 1\n",
    "\n",
    "        #========================================Gathering Education information-------\n",
    "\n",
    "        splitted = read.split('\\n')\n",
    "        start=0\n",
    "        for index,i in enumerate(splitted):\n",
    "            if i =='Education':\n",
    "                start=index+1\n",
    "\n",
    "        eduList=splitted[start:-1]\n",
    "        if len(eduList)%2!=0:\n",
    "            eduList=eduList[:-1]\n",
    "        realEduList=[]\n",
    "        MasterList=['Masters','Master','M Sc ', 'M.Sc ','MS ','M S ','Master of Science','Master of Arts','MBA']\n",
    "        BachelorList=['Bachelor','Bachelors', 'B Sc ', 'B.Sc ','BS ','B S ','Bachelor of Science ', 'Bachelor of Arts ','Associate of Science ','Associate ']\n",
    "        DoctoralList=['Doctor of Philosophy','PhD']\n",
    "        collegeList=['high school','university','college','academy','institute','international center']\n",
    "        for index1,e in enumerate(eduList):\n",
    "            if any(word.lower() in e.lower() for word in collegeList) and e!=eduList[-1]: \n",
    "                Start='N/A'\n",
    "                End='N/A'\n",
    "                Degree='N/A'\n",
    "                Course='N/A'\n",
    "                courseTerm = eduList[index1+1]\n",
    "                if re.search(r'.*([1-3][0-9]{3})', eduList[index1+1]):\n",
    "                    courseTerm = eduList[index1+1]\n",
    "                elif e!=eduList[-2]:\n",
    "                    if re.search(r'.*([1-3][0-9]{3})', eduList[index1+2]):\n",
    "                        courseTerm = eduList[index1+1]+ ' '+eduList[index1+2]\n",
    "                if any(word.lower() in courseTerm.lower() for word in MasterList):\n",
    "                    Degree='Master'\n",
    "                elif any(word.lower() in courseTerm.lower() for word in BachelorList):\n",
    "                    Degree='Bachelor'\n",
    "                elif any(word.lower() in courseTerm.lower() for word in DoctoralList):\n",
    "                    Degree='Doctoral'\n",
    "                if any(char.isdigit() for char in courseTerm):\n",
    "                    firstDigit = re.search(r\"\\d\", courseTerm).start()\n",
    "                    eduDates=courseTerm[firstDigit:].strip().split('-')\n",
    "                    Course=courseTerm[0:firstDigit].strip()[:-1]\n",
    "                    if len(eduDates)>=1:\n",
    "                        Start= eduDates[0]\n",
    "                    if len(eduDates)>=2:\n",
    "                        End= eduDates[1]\n",
    "                else:\n",
    "                    Course=courseTerm.strip()[:-1]\n",
    "                realEduList.append({'Institution':e.strip(),\n",
    "                                   'Course':Course,\n",
    "                                    'Start':Start,\n",
    "                                    'End':End,\n",
    "                                    'Degree':Degree\n",
    "                                    })\n",
    "        #========================================Gathering Experience information-------\n",
    "        name=splitted[0]\n",
    "        location=splitted[1]\n",
    "        expStartIndex=0\n",
    "        expEndIndex=start\n",
    "        for ind,e in enumerate(splitted):\n",
    "            if e=='Experience':\n",
    "                expStartIndex=ind+1\n",
    "        experiences=splitted[expStartIndex:expEndIndex]\n",
    "\n",
    "        jobs=[]\n",
    "        experienceList=[]\n",
    "        for i in range(len(experiences)):\n",
    "            x=re.findall('\\(.*?\\)',experiences[i])\n",
    "            if x and any(char.isdigit() for char in x[0]) and ('year' in x[0] or 'month' in x[0]) and ' at ' in experiences[i-1]:\n",
    "                experienceList.append(i)\n",
    "                startDate='N/A'\n",
    "                endDate='N/A'\n",
    "                dates=experiences[i].split('-')\n",
    "                if len(dates)>=1:\n",
    "                    startDate=dates[0].strip()\n",
    "                if len(dates)>=2:\n",
    "                    endDate=dates[1][:dates[1].find('(')].strip()\n",
    "                month=0\n",
    "                year=0\n",
    "                temp = x[0][1:-1].split(\" \")\n",
    "                if temp[0].isnumeric(): \n",
    "                    if len(temp) > 2 and temp[2].isnumeric():\n",
    "                        month+=int(temp[2])\n",
    "                        year += int(temp[0])\n",
    "                    elif(temp[1]=='year' or temp[1]=='years'):\n",
    "                        year+=int(temp[0])\n",
    "                    else:\n",
    "                        month+=int(temp[0])\n",
    "                    year += (month/12)\n",
    "                    year = round(year,1)        \n",
    "                comp=experiences[i-1].split(' at ')\n",
    "                jobs.append({'Title':comp[0].strip(),\n",
    "                             'Company':comp[1].strip(),\n",
    "                            'Start':startDate,\n",
    "                            'End':endDate,\n",
    "                            'totalYearsInCompany':(str(year)+' years')})\n",
    "        # extracting job description of all the jobs        \n",
    "        for m in range(len(experienceList)):\n",
    "            if experienceList[m]!=experienceList[-1]:\n",
    "                if experienceList[m]+2==experienceList[m+1]:\n",
    "                    jobs[m]['Description']='N/A'\n",
    "                else:\n",
    "                    description=''\n",
    "                    for d in experiences[experienceList[m]+1:experienceList[m+1]-1]:\n",
    "                        description=(description + ' '+ d.strip()).strip()\n",
    "                    jobs[m]['Description']=description    \n",
    "            else:\n",
    "                if len(experiences)==experienceList[m]+1:\n",
    "                    jobs[m]['Description']='N/A'\n",
    "                else:\n",
    "                    description=''\n",
    "                    for d in experiences[experienceList[m]+1:]:\n",
    "                        description=(description + ' '+ d.strip()).strip()\n",
    "                    jobs[m]['Description']=description\n",
    "        #================= Storing the data in firebase------------\n",
    "        final_dict={'name':name,\n",
    "                    'location':location,\n",
    "                    'email':'N/A',\n",
    "                    'phone':'N/A',\n",
    "                    'background':{'career':jobs,\n",
    "                                 'education':realEduList},\n",
    "                   'skills':{\n",
    "                       'applications':applications,\n",
    "                       'langauges':languages,\n",
    "                       'methods':methods,\n",
    "                       'delivery':delivery,\n",
    "                       'impact':impact,\n",
    "                       'communication':communication\n",
    "                   }}\n",
    "\n",
    "        canList.append(final_dict)\n",
    "        print(resume+\" Done\")\n",
    "        \n",
    "    mycred = credentials.Certificate('dev-key.json')\n",
    "\n",
    "    try:\n",
    "        firebase_admin.initialize_app(mycred)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    db = firestore.client()\n",
    "\n",
    "    for c in canList:\n",
    "        doc_ref = db.collection('users1').document()\n",
    "        doc_ref.set(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudar\\Desktop\\resume\\ingested files\\Test SAGs\\1. LI_Profile_Export_1.+Data+Scientist+-+D.C.+-+Top+Secret_20200714.pdf\n",
      "Resume1.pdf Done\n",
      "Resume2.pdf Done\n",
      "Resume3.pdf Done\n",
      "Resume4.pdf Done\n",
      "Resume5.pdf Done\n",
      "Resume6.pdf Done\n",
      "Resume7.pdf Done\n",
      "Resume8.pdf Done\n",
      "File Done\n",
      "C:\\Users\\sudar\\Desktop\\resume\\ingested files\\Test SAGs\\2. LI_Profile_Export_SAGs+in+Data+Science_20200712.pdf\n",
      "Resume1.pdf Done\n",
      "Resume2.pdf Done\n",
      "Resume3.pdf Done\n",
      "Resume4.pdf Done\n",
      "Resume5.pdf Done\n",
      "Resume6.pdf Done\n",
      "Resume7.pdf Done\n",
      "Resume8.pdf Done\n",
      "Resume9.pdf Done\n",
      "Resume10.pdf Done\n",
      "Resume11.pdf Done\n",
      "Resume12.pdf Done\n",
      "Resume13.pdf Done\n",
      "Resume14.pdf Done\n",
      "Resume15.pdf Done\n",
      "Resume16.pdf Done\n",
      "Resume17.pdf Done\n",
      "Resume18.pdf Done\n",
      "Resume19.pdf Done\n",
      "Resume20.pdf Done\n",
      "Resume21.pdf Done\n",
      "Resume22.pdf Done\n",
      "Resume23.pdf Done\n",
      "Resume24.pdf Done\n",
      "Resume25.pdf Done\n",
      "File Done\n"
     ]
    }
   ],
   "source": [
    "#========================================Getting the pdfs from directory-------\n",
    "import os\n",
    "directory = r'C:\\Users\\sudar\\Desktop\\resume\\ingested files\\Test SAGs'\n",
    "pathList=[]\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pathList.append(os.path.join(directory, filename))\n",
    "    else:\n",
    "        continue\n",
    "for p in pathList:\n",
    "    print(p)\n",
    "    finalList=linkedin_resume_parser(p)\n",
    "    print('File Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesize = os.path.getsize(\"Resume2.pdf\")\n",
    "type(filesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from docx2pdf import convert\n",
    "from pdfminer.layout import LAParams\n",
    "from pyresparser import ResumeParser\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "import pdfplumber\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import db\n",
    "def get_text_from_pdf(path):\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        retstr = io.StringIO()\n",
    "        codec = 'utf-8'\n",
    "\n",
    "        laparams = LAParams(line_overlap=.6, char_margin=1.5, line_margin=1.1, word_margin=0.3, boxes_flow=.6,\n",
    "                             detect_vertical=False, all_texts=False)\n",
    "        device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "        fp = open(path, 'rb')\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        password = \"\"\n",
    "        maxpages = 0\n",
    "        caching = True\n",
    "        pagenos = set()\n",
    "        for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching,\n",
    "                                      check_extractable=True):\n",
    "            interpreter.process_page(page)\n",
    "        fp.close()\n",
    "        device.close()\n",
    "        string = retstr.getvalue()\n",
    "\n",
    "        retstr.close()\n",
    "        return string\n",
    "    \n",
    "        #====================================Cleaning the raw text============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume4.pdf Done\n",
      "Resume5.pdf Done\n",
      "Resume6.pdf Done\n",
      "Resume7.pdf Done\n",
      "Resume8.pdf Done\n",
      "Resume9.pdf Done\n",
      "Resume10.pdf Done\n",
      "Resume11.pdf Done\n",
      "Resume12.pdf Done\n",
      "Resume13.pdf Done\n",
      "Resume14.pdf Done\n",
      "Resume15.pdf Done\n",
      "Resume16.pdf Done\n",
      "Resume17.pdf Done\n",
      "Resume18.pdf Done\n",
      "Resume19.pdf Done\n",
      "Resume20.pdf Done\n",
      "Resume21.pdf Done\n",
      "Resume22.pdf Done\n",
      "Resume23.pdf Done\n",
      "Resume1.pdf Done\n",
      "Resume25.pdf Done\n",
      "Resume26.pdf Done\n"
     ]
    }
   ],
   "source": [
    "canList=[]\n",
    "# 'Resume1.pdf','Resume2.pdf','Resume3.pdf','Resume4.pdf','Resume5.pdf','Resume6.pdf','Resume7.pdf',\n",
    "# 'Resume8.pdf','Resume9.pdf','Resume10.pdf',\n",
    "#              'Resume11.pdf','Resume12.pdf',\n",
    "pdfNameList=['Resume4.pdf','Resume5.pdf','Resume6.pdf','Resume7.pdf','Resume8.pdf','Resume9.pdf','Resume10.pdf',\n",
    "             'Resume11.pdf','Resume12.pdf','Resume13.pdf','Resume14.pdf','Resume15.pdf','Resume16.pdf','Resume17.pdf',\n",
    "             'Resume18.pdf','Resume19.pdf','Resume20.pdf','Resume21.pdf','Resume22.pdf','Resume23.pdf','Resume1.pdf',\n",
    "            'Resume25.pdf','Resume26.pdf']\n",
    "for resume in pdfNameList:\n",
    "    read = get_text_from_pdf(resume)\n",
    "    read = read.replace('\\u25c6',' ')\n",
    "    read = read.replace('➤➤',' ')\n",
    "    read = read.replace('•',' ')\n",
    "    read = read.replace('▶️',' ')\n",
    "    read = read.replace('□',' ')\n",
    "    read = read.replace('\\x0c','')\n",
    "    read = read.replace('\\xa0','')\n",
    "\n",
    "    read = read.replace('\\n\\n','\\n')\n",
    "\n",
    "    #========================================Gathering Skills information-------\n",
    "    languages = {}\n",
    "    applications = {}\n",
    "    methods = {}\n",
    "    delivery = {}\n",
    "    impact ={}\n",
    "    communication = {}\n",
    "\n",
    "    lang = ['C#/.NET', 'C/C++', 'Go', 'Java', 'Javascript', 'Julia', 'MATLAB', 'PHP', 'R', 'Ruby', 'Scala', 'Visual Basic/VBA', 'Python', 'SQL', 'SAS']\n",
    "    appli = ['Computer Vision', 'Advesarial Machine Learning','Machine Learning', 'Auto-ML', 'Basic Neural Networks', 'Neural Networks', 'Linear Regression', 'Logistic Regression', 'Regression','Convolutional Neural Networks', 'Generative Models', 'LSTMs', 'LSTM', 'Natural Language Processing', 'NLP', 'Predictive Models', 'Recurrent Neural Networks', 'Reinforcement Learning', 'Supervised Learning', 'Unsupervised Learning', 'Voice & Audio Processing']\n",
    "    metho = ['Clustering','Data Analysis', 'Data Extraction', ' Data Compilation', 'Data Cleaning', 'Decision Analysis', 'Design of Experiments', 'Discrete Event Simulation', 'Game Theory', 'Linear & Integer Optimization', 'Multivariate Testing', 'Nonparametric Statistics', 'Parametric Statistics', 'Segmentation', 'Simulation', 'Monte Carlo', 'Stochastic Programming']\n",
    "    deliv = ['Alteryx Analytics','Amazon Web Services','AWS', 'Anaconda','Apache Airflow','Apache Beam','Apache Hadoop','Hadoop','Hive','Apache Hive','Apache Spark','Apachec Kafka','Kafka','Caffe','Cassandra','Cloudera Workbench','Couchbase','Databricks','Dataiku','DataScience.com','Docker','Domino','Google Bigtable','Google Cloud Platform','GCP','H2O.ai','IBM Watson Studio','Keras','KNIME Analytics','Kubernetes/Kubeflow','MapReduce','MATLAB','MATLAB/Octave','Microsoft Azure','Azure','Microsoft R','MongoDB','MXnet','MySQL','Pandas','PostgreSQL','RapidMiner Studio','SAP Predictive Analytics','SAS Enterprise Miner', 'SAS EM', 'SAS', 'Tableau','TensorFlow','Teradata Analytics','TIBCO Data Science','Wolfram Mathematica']\n",
    "    imp = ['Asset Utilization','Churn Prevention','Cost Optimization','Cross-/Upselling','Customer Analysis','Customer Experience','Debt Management','Demand Planning','E-Commerce','Fraud Prevention','Marketing Spend','Operational efficiencies','Predictive Maintenance','Pricing','Product Development','Promotion Optimization','Research & Development','Supply Chain Optimization','Workforce Planning']\n",
    "    comm = ['Presentation Skills','Storytelling','Data Visualization','Writing Skills','Social Media Skills','Emotional Intelligence','Business Acumen']\n",
    "\n",
    "\n",
    "    res=read.lower()\n",
    "    skills=[]\n",
    "    for i in lang:\n",
    "        if res.find(' '+i.lower()+' ') != -1:\n",
    "            languages[i] = 1\n",
    "\n",
    "\n",
    "    for j in appli:\n",
    "        if res.find(' '+j.lower()+' ') != -1:\n",
    "            applications[j] = 1\n",
    "\n",
    "    for k in metho:\n",
    "        if res.find(' '+k.lower()+' ') != -1:\n",
    "            methods[k] = 1\n",
    "\n",
    "    for l in deliv:\n",
    "        if res.find(' '+l.lower()+' ') != -1:\n",
    "            delivery[l] = 1\n",
    "\n",
    "    for m in imp:\n",
    "        if res.find(' '+m.lower()+' ') != -1:\n",
    "            impact[m] = 1\n",
    "\n",
    "    for n in comm:\n",
    "        if res.find(' '+n.lower()+' ') != -1:\n",
    "            communication[n] = 1\n",
    "\n",
    "    #========================================Gathering Education information-------\n",
    "\n",
    "    splitted = read.split('\\n')\n",
    "    start=0\n",
    "    for index,i in enumerate(splitted):\n",
    "        if i =='Education':\n",
    "            start=index+1\n",
    "\n",
    "    eduList=splitted[start:-1]\n",
    "    if len(eduList)%2!=0:\n",
    "        eduList=eduList[:-1]\n",
    "    realEduList=[]\n",
    "    MasterList=['Masters','Master','M Sc ', 'M.Sc ','MS ','M S ','Master of Science','Master of Arts','MBA']\n",
    "    BachelorList=['Bachelor','Bachelors', 'B Sc ', 'B.Sc ','BS ','B S ','Bachelor of Science ', 'Bachelor of Arts ','Associate of Science ','Associate ']\n",
    "    DoctoralList=['Doctor of Philosophy','PhD']\n",
    "    collegeList=['high school','university','college','academy','institute','international center']\n",
    "    for index1,e in enumerate(eduList):\n",
    "        if any(word.lower() in e.lower() for word in collegeList) and e!=eduList[-1]: \n",
    "            Start='N/A'\n",
    "            End='N/A'\n",
    "            Degree='N/A'\n",
    "            Course='N/A'\n",
    "            courseTerm = eduList[index1+1]\n",
    "            if re.search(r'.*([1-3][0-9]{3})', eduList[index1+1]):\n",
    "                courseTerm = eduList[index1+1]\n",
    "            elif e!=eduList[-2]:\n",
    "                if re.search(r'.*([1-3][0-9]{3})', eduList[index1+2]):\n",
    "                    courseTerm = eduList[index1+1]+ ' '+eduList[index1+2]\n",
    "            if any(word.lower() in courseTerm.lower() for word in MasterList):\n",
    "                Degree='Master'\n",
    "            elif any(word.lower() in courseTerm.lower() for word in BachelorList):\n",
    "                Degree='Bachelor'\n",
    "            elif any(word.lower() in courseTerm.lower() for word in DoctoralList):\n",
    "                Degree='Doctoral'\n",
    "            if any(char.isdigit() for char in courseTerm):\n",
    "                firstDigit = re.search(r\"\\d\", courseTerm).start()\n",
    "                eduDates=courseTerm[firstDigit:].strip().split('-')\n",
    "                Course=courseTerm[0:firstDigit].strip()[:-1]\n",
    "                if len(eduDates)>=1:\n",
    "                    Start= eduDates[0]\n",
    "                if len(eduDates)>=2:\n",
    "                    End= eduDates[1]\n",
    "            else:\n",
    "                Course=courseTerm.strip()[:-1]\n",
    "            realEduList.append({'Institution':e.strip(),\n",
    "                               'Course':Course,\n",
    "                                'Start':Start,\n",
    "                                'End':End,\n",
    "                                'Degree':Degree\n",
    "                                })\n",
    "    #========================================Gathering Experience information-------\n",
    "    name=splitted[0]\n",
    "    location=splitted[1]\n",
    "    expStartIndex=0\n",
    "    expEndIndex=start\n",
    "    for ind,e in enumerate(splitted):\n",
    "        if e=='Experience':\n",
    "            expStartIndex=ind+1\n",
    "    experiences=splitted[expStartIndex:expEndIndex]\n",
    "\n",
    "    jobs=[]\n",
    "    experienceList=[]\n",
    "    for i in range(len(experiences)):\n",
    "        x=re.findall('\\(.*?\\)',experiences[i])\n",
    "        if x and any(char.isdigit() for char in x[0]) and ('year' in x[0] or 'month' in x[0]) and ' at ' in experiences[i-1]:\n",
    "            experienceList.append(i)\n",
    "            startDate='N/A'\n",
    "            endDate='N/A'\n",
    "            dates=experiences[i].split('-')\n",
    "            if len(dates)>=1:\n",
    "                startDate=dates[0].strip()\n",
    "            if len(dates)>=2:\n",
    "                endDate=dates[1][:dates[1].find('(')].strip()\n",
    "            month=0\n",
    "            year=0\n",
    "            temp = x[0][1:-1].split(\" \")\n",
    "            if temp[0].isnumeric(): \n",
    "                if len(temp) > 2 and temp[2].isnumeric():\n",
    "                    month+=int(temp[2])\n",
    "                    year += int(temp[0])\n",
    "                elif(temp[1]=='year' or temp[1]=='years'):\n",
    "                    year+=int(temp[0])\n",
    "                else:\n",
    "                    month+=int(temp[0])\n",
    "                year += (month/12)\n",
    "                year = round(year,1)        \n",
    "            comp=experiences[i-1].split(' at ')\n",
    "            jobs.append({'Title':comp[0].strip(),\n",
    "                         'Company':comp[1].strip(),\n",
    "                        'Start':startDate,\n",
    "                        'End':endDate,\n",
    "                        'totalYearsInCompany':(str(year)+' years')})\n",
    "    # extracting job description of all the jobs        \n",
    "    for m in range(len(experienceList)):\n",
    "        if experienceList[m]!=experienceList[-1]:\n",
    "            if experienceList[m]+2==experienceList[m+1]:\n",
    "                jobs[m]['Description']='N/A'\n",
    "            else:\n",
    "                description=''\n",
    "                for d in experiences[experienceList[m]+1:experienceList[m+1]-1]:\n",
    "                    description=(description + ' '+ d.strip()).strip()\n",
    "                jobs[m]['Description']=description    \n",
    "        else:\n",
    "            if len(experiences)==experienceList[m]+1:\n",
    "                jobs[m]['Description']='N/A'\n",
    "            else:\n",
    "                description=''\n",
    "                for d in experiences[experienceList[m]+1:]:\n",
    "                    description=(description + ' '+ d.strip()).strip()\n",
    "                jobs[m]['Description']=description\n",
    "    #================= Storing the data in firebase------------\n",
    "    final_dict={'name':name,\n",
    "                'location':location,\n",
    "                'email':'N/A',\n",
    "                'phone':'N/A',\n",
    "                'background':{'career':jobs,\n",
    "                             'education':realEduList},\n",
    "               'skills':{\n",
    "                   'applications':applications,\n",
    "                   'langauges':languages,\n",
    "                   'methods':methods,\n",
    "                   'delivery':delivery,\n",
    "                   'impact':impact,\n",
    "                   'communication':communication\n",
    "               }}\n",
    "\n",
    "    canList.append(final_dict)\n",
    "    print(resume+\" Done\")\n",
    "\n",
    "mycred = credentials.Certificate('dev-key.json')\n",
    "\n",
    "try:\n",
    "    firebase_admin.initialize_app(mycred)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "db = firestore.client()\n",
    "\n",
    "for c in canList:\n",
    "    doc_ref = db.collection('users1').document()\n",
    "    doc_ref.set(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough Work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6031"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import db\n",
    "\n",
    "mycred = credentials.Certificate('dev-key.json')\n",
    "\n",
    "try:\n",
    "    firebase_admin.initialize_app(mycred)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "db = firestore.client()\n",
    "\n",
    "\n",
    "all_docs = db.collection('users1').stream()\n",
    "\n",
    "usersKeyList=[doc.to_dict() for doc in all_docs]\n",
    "\n",
    "len(usersKeyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudar\\Desktop\\resume\\TEST\\LI_Profile_Export_Search_20200725 (32).pdf\n",
      "C:\\Users\\sudar\\Desktop\\resume\\TEST\\LI_Profile_Export_Search_20200725 (33).pdf\n",
      "C:\\Users\\sudar\\Desktop\\resume\\TEST\\LI_Profile_Export_Search_20200725 (34).pdf\n",
      "C:\\Users\\sudar\\Desktop\\resume\\TEST\\LI_Profile_Export_Search_20200725 (35).pdf\n",
      "C:\\Users\\sudar\\Desktop\\resume\\TEST\\LI_Profile_Export_Search_20200725 (36).pdf\n",
      "C:\\Users\\sudar\\Desktop\\resume\\TEST\\LI_Profile_Export_Search_20200725 (37).pdf\n",
      "C:\\Users\\sudar\\Desktop\\resume\\TEST\\LI_Profile_Export_Search_20200725.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = r'C:\\Users\\sudar\\Desktop\\resume\\TEST'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        print(os.path.join(directory, filename))\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
